{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente es una descripción básica para implementar flujos ETL (_Extract, Transform and Load_) en Python, utilizando la librería [`pygrametl`](https://chrthomsen.github.io/pygrametl/doc/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente caso consiste en un ejemplo simulado de un almacén de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/dm_ventas.vuerd.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El almacén de datos tiene una tabla de hechos y tres dimensiones organizadas en un __esquema estrella__. \n",
    "- La __tabla de hechos__ almacena datos de la cantidad de libros que se venden cada día. \n",
    "- La __dimensión Libro__ almacena el nombre y género de cada libro vendido.\n",
    "- La __dimensión Localizacion__ almacena la comuna y región de los clientes.\n",
    "- La __dimensión Tiempo__ almacena la fecha de cada venta. \n",
    "\n",
    "Para efectos de baja complejidad, ninguna de las dimensiones tiene forma de copo de nieve, tampoco contienen atributos que cambie lentamente. Sin embargo, la librería pygrametl es compatible con dichas características, si este fuera el caso ([más información](https://chrthomsen.github.io/pygrametl/doc/api/pygrametl.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para introducir los datos en el flujo ETL, se utilizan __dos fuentes de datos__: \n",
    "- La __base de datos__ (sistema OLTP) que contiene los registros de ventas\n",
    "- Un __archivo CSV__ que contiene información de las comunas por regiones de Chile (obtenido desde [https://www.subdere.gov.cl/](https://www.subdere.gov.cl/documentacion/regiones-provincias-y-comunas-de-chile-2011)). Esta información es usada para complementar la dimensión Localización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión con RDBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se necesita crear conexiones a las dos bases de datos, que contiene los registros de ventas y el almacenén de datos, respectivamente. Estas conexiones deben ser conexiones [PEP 249](https://www.python.org/dev/peps/pep-0249/).\n",
    "\n",
    "\n",
    "- Para establecer una conexión a RDBMS (_Relational Database Management System_), [`MySQL connector`](https://dev.mysql.com/doc/connector-python/en/) es una API que cumple con especificación Python Database API (PEP 249).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysql.connector import connect, Error, errorcode\n",
    "\n",
    "def conexion(host, dbname, user, pwd):\n",
    "    \"\"\"\n",
    "    Retorna un objeto conexión.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = connect(user=user, password=pwd, host=host, database=dbname)\n",
    "        print('Conexión a {} establecida con exito!'.format(dbname))\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        if e.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "            print('Algo anda mal con tu usuario o contraseña.')\n",
    "        elif e.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "            print('La base de datos no existe.')\n",
    "        else:\n",
    "            print(e)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión con archivos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la extracción de filas de un archivo CSV no requiere una conexión PEP 249, solo un controlador de archivo abierto.\n",
    "- pygrametl usa `DictReader` de Python para archivos CSV.\n",
    "- Asume que el encabezado del archivo CSV contiene el nombre de cada columna. \n",
    "- Al usar `CSVSource`, es importante convertir los valores al tipo correcto antes de insertarlos en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygrametl.datasources import CSVSource\n",
    "\n",
    "region_file_handle = open('./data/cut_2010_v02.csv', 'r')\n",
    "region_source = CSVSource(f=region_file_handle, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTA:__ La mayoría de las __abstracciones de la librería pigrametl producen, consumen y operan datos en forma de _registro___. Considere que un _registro_ es un diccionario cuyos nombres de las columnas son las claves, y los valores son los datos que contiene cada _registro_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperar datos a partir de consulta SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión a Libreria establecida con exito!\n"
     ]
    }
   ],
   "source": [
    "from pygrametl.datasources import SQLSource\n",
    "\n",
    "cnx_libreria = conexion('localhost', 'Libreria', 'root', 'mysqlroot')\n",
    "query = \"\"\"\n",
    "    SELECT date(Pedido.Fecha) as 'fecha',\n",
    "        Libro.Titulo AS 'libro',\n",
    "        Genero.Nombre AS 'genero',\n",
    "        Comuna.Nombre AS 'comuna',\n",
    "        sum(Pedido.Cantidad) AS 'cantidad'\n",
    "    FROM Pedido\n",
    "    INNER JOIN Libro ON Libro.LibroID = Pedido.LibroID\n",
    "    INNER JOIN Genero ON Genero.GeneroID = Libro.GeneroID\n",
    "    INNER JOIN Cliente ON Cliente.ClienteID = Pedido.ClienteID\n",
    "    INNER JOIN Comuna ON Comuna.ComunaID = Cliente.ComunaID\n",
    "    GROUP BY fecha, libro, genero, comuna;\n",
    "    \"\"\"\n",
    "\n",
    "name_mapping = 'Fecha', 'Titulo', 'Genero', 'Comuna', 'Cantidad'\n",
    "ventas_source = SQLSource(connection=cnx_libreria, query=query, names=name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la fecha obtenida desde la base de datos __Libreria__ se obtienen nuevos atributos para poblar la dimensión Tiempo. Para esto, se diseñan dos funciones, una para divir la fehca en __dia, mes y año__, y la otra, para obtener el trimestre al que corresponde dicha fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dmY(row):\n",
    "    \"\"\"Agrega los componente de la fecha al registro (row)\n",
    "\n",
    "    Args:\n",
    "        row (dict): Registros que se carga en el almacen\n",
    "    \"\"\"\n",
    "\n",
    "    fecha = row['Fecha']\n",
    "    row['Dia'] = fecha.day\n",
    "    row['Mes'] = fecha.month\n",
    "    row['Anio'] = fecha.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trimestre(row):\n",
    "    \"\"\"Agrega el trimestre al registro (row) \n",
    "\n",
    "    Args:\n",
    "        row (dict): Registros que se carga en el almacen\n",
    "    \"\"\"\n",
    "    \n",
    "    if row['Mes'] < 4:\n",
    "        trimestre = 1\n",
    "    elif row['Mes'] < 7:\n",
    "        trimestre = 2\n",
    "    elif row['Mes'] < 10:\n",
    "        trimestre = 3\n",
    "    else:\n",
    "        trimestre = 4\n",
    "        \n",
    "    row['Trimestre'] = trimestre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexion con el almacén de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ConnectionWrapper` comparte automáticamente entre abstracciones de pygrametl, se guarda en una variable para que la conexión se pueda cerrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión a VentasDM establecida con exito!\n"
     ]
    }
   ],
   "source": [
    "from pygrametl import ConnectionWrapper\n",
    "\n",
    "cnx_dm = conexion('localhost', 'VentasDM', 'root', 'mysqlroot')\n",
    "cnx_dm_wrapper = ConnectionWrapper(connection=cnx_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pygrametl proporciona diversos tipos de abstracciones para dimensiones y tablas de hechos. En este ejemplo, se usan las más simples.\n",
    "- `CachedDimension` crea una instancia de para cada dimensión en el almacén de datos. \n",
    "- `CachedDimension` usa un caché local para reducir significativamente la cantidad de solicitudes emitidas al RDBMS. \n",
    "\n",
    "Para cada dimensión, __se proporciona el nombre de la tabla de la base de datos, la clave principal de la tabla y las columnas sin clave (atributos) de la tabla__. \n",
    "\n",
    "Además, para la __dimensión de Localicalizacion__, se proporciona el subconjunto de los atributos que se deben usar para buscar la clave principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygrametl.tables import CachedDimension, FactTable\n",
    "\n",
    "libro_dim = CachedDimension(\n",
    "        name='Libro',\n",
    "        key='LibroID',\n",
    "        attributes=['Titulo', 'Genero'])\n",
    "\n",
    "tiempo_dim = CachedDimension(\n",
    "        name='Tiempo',\n",
    "        key='TiempoID',\n",
    "        attributes=['Fecha', 'Dia', 'Mes', 'Anio', 'Trimestre'])\n",
    "\n",
    "localizacion_dim = CachedDimension(\n",
    "        name='Localizacion',\n",
    "        key='LocalizacionID',\n",
    "        attributes=['Comuna', 'Region'],\n",
    "        lookupatts=['Comuna'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea una instancia de `FactTable` para la tabla de hechos del almacén de datos, a partir, del nombre de la tabla, una lista de columnas que constituyen la clave principal de la tabla de hechos y una lista de las medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_ft = FactTable(\n",
    "        name='Ventas',\n",
    "        keyrefs=['LibroID', 'LocalizacionID', 'TiempoID'],\n",
    "        measures=['Cantidad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La __dimensión Localizacion__ se completa con datos del archivo CSV, ya que el archivo contiene toda la información necesaria para ambas columnas de la tabla. Para insertar las filas se usa el método `CachedDimension.insert()`\n",
    "\n",
    "__NOTA__: Si la dimensión Localizacion se completara solo con los datos de la base de datos Libreria, sería necesario actualizar el atributo de región con datos del archivo CSV cada vez que se actualicen los datos del almacen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in region_source:\n",
    "    localizacion_dim.insert({'Comuna': row['Nombre Comuna'], 'Region': row['Nombre Región']})\n",
    "\n",
    "region_file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se cargan los datos en las __dimensiones Libro, Tiempo, y también en la tabla de hechos__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ventas_source:\n",
    "    # Se divide la fecha\n",
    "    set_dmY(row)\n",
    "    \n",
    "    # Se obtiene el trimestre\n",
    "    set_trimestre(row)\n",
    "\n",
    "    # La fila se actualiza con las claves primarias correctas para \n",
    "    # cada dimensión y cualquier dato nuevo se inserta en cada una \n",
    "    # de las dimensiones al mismo tiempo.\n",
    "    row['LibroID'] = libro_dim.ensure(row)\n",
    "    row['TiempoID'] = tiempo_dim.ensure(row)\n",
    "\n",
    "    # CachedDimension.ensure() no se utiliza para la dimensión Localizacion \n",
    "    # porque ya se ha rellenado. En su lugar, se utiliza el método \n",
    "    # CachedDimension.lookup() que no inserta ningún dato y devuelve el \n",
    "    # valor None si no está disponible una fila con las búsquedas correctas. \n",
    "    # En este caso, se genera un error si falta una ubicación en el archivo \n",
    "    # CSV, ya que la recuperación no es posible.\n",
    "    row['LocalizacionID'] = localizacion_dim.lookup(row)\n",
    "    if not row['LocalizacionID']:\n",
    "        raise ValueError(\"La comuna no se encuantra en la dimension Localizacion\")\n",
    "\n",
    "    # Considerando que la cantidad de ordenes se presenta como un valor agregado \n",
    "    # en los registros de ventas, la fila se puede insertar en el almacén de datos. \n",
    "    # De lo contrario, se debería realizar la transformacion antes de insertar.\n",
    "    ventas_ft.insert(row)\n",
    "\n",
    "# Después de que se hayan insertado todos los datos, se ordena a la conexión que se \n",
    "# confirme la insersión y luego se cierra. Esto garantiza que los datos se\n",
    "# confirmen en la base de datos y que los recursos utilizados por la conexión se\n",
    "# liberen.\n",
    "cnx_dm_wrapper.commit()\n",
    "cnx_dm_wrapper.close()\n",
    "\n",
    "# Finalmente, se cierra la conexión a la base de datos Libreria\n",
    "cnx_libreria.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('etl38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabe0d710f3a253e096a9527723e238a8c0c435f5b953a78fc3c7747ee356b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

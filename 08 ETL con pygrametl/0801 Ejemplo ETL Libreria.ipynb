{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL básico con `pygrametl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "La siguiente es una descripción básica para implementar flujos ETL (_Extract, Transform and Load_) en Python, utilizando la librería [`pygrametl`](https://chrthomsen.github.io/pygrametl/doc/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "__NOTA__: Se requiere de la instalación de las siguientes tecnologías:\n",
    "\n",
    "- Python v3.9.18\n",
    "- [MySQL Connector/Python](https://dev.mysql.com/doc/connector-python/en/) v8.0.18\n",
    "- Libreria [pygrametl](http://chrthomsen.github.io/pygrametl/) v2.8 "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto\n",
    "\n",
    "El siguiente caso consiste en un ejemplo simulado de un almacén de datos.\n",
    "\n",
    "<img src=\"./img/erd-ventas_dm.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El almacén de datos tiene una tabla de hechos y tres dimensiones organizadas en un __esquema estrella__. \n",
    "- La __tabla de hechos__ almacena datos de la cantidad de libros que se venden cada día. \n",
    "- La __dimensión libro__ almacena el nombre y género de cada libro vendido.\n",
    "- La __dimensión localizacion__ almacena la comuna y región de los clientes.\n",
    "- La __dimensión tiempo__ almacena la fecha de cada venta. \n",
    "\n",
    "Para efectos de baja complejidad, ninguna de las dimensiones tiene forma de copo de nieve, las dimensiones tampoco contienen atributos que cambien lentamente. Sin embargo, la librería `pygrametl` es compatible con dichas características, si este fuera el caso ([más información](https://chrthomsen.github.io/pygrametl/doc/api/pygrametl.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos utilizados provienen desde __dos fuentes__: \n",
    "- La __base de datos libreria__ (sistema OLTP) que contiene los registros de ventas de libros.\n",
    "- Un __archivo CSV__ que contiene información de las comunas por regiones de Chile (obtenido desde [https://www.subdere.gov.cl/](https://www.subdere.gov.cl/documentacion/regiones-provincias-y-comunas-de-chile-2011)). Esta información es usada para complementar la dimensión __localizacion__ del almacen de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracción desde archivos\n",
    "\n",
    "Para la extracción de filas de un archivo CSV solo se requiere de un controlador de archivo abierto.\n",
    "- `pygrametl` usa `DictReader` de Python para archivos CSV.\n",
    "- Asume que el encabezado del archivo CSV contiene el nombre de cada columna.\n",
    "- Al usar `CSVSource`, es importante convertir los valores al tipo correcto antes de insertarlos en una tabla de la base de datos.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pygrametl.datasources import CSVSource\n",
    "\n",
    "region_file_handle = open('./data/cut_2010_v02.csv', 'r', encoding=\"utf-8\")\n",
    "region_source = CSVSource(f=region_file_handle, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción desde RDBMS\n",
    "\n",
    "Para extraer datos desde un RDBMS, es necesario crear conexiones a la base de datos. Esta conexión deben ser conexiones [PEP 249](https://www.python.org/dev/peps/pep-0249/).\n",
    "- [`MySQL connector`](https://dev.mysql.com/doc/connector-python/en/) es una API que cumple con especificación Python Database API (PEP 249)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mysql.connector import connect, Error, errorcode\n",
    "\n",
    "def conexion(host, dbname, user, pwd):\n",
    "    \"\"\"Retorna un objeto de tipo conexión.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = connect(user=user, password=pwd, host=host, database=dbname)\n",
    "        print('Conexión a {} establecida con exito!'.format(dbname))\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        if e.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "            print('Algo anda mal con tu usuario o contraseña.')\n",
    "        elif e.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "            print('La base de datos no existe.')\n",
    "        else:\n",
    "            print(e)\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- La mayoría de las abstracciones de la librería `pigrametl` __producen, consumen y operan datos en forma de _registro___.\n",
    "- Considere que un _registro_ es un diccionario cuyos nombres de las columnas son las claves, y los valores son los datos que contiene cada _registro_.\n",
    "\n",
    "A continuación se presenta un ejemplo de extracción de datos desde la base de datos __libreria__."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygrametl.datasources import SQLSource\n",
    "\n",
    "cnx_libreria = conexion('localhost', 'libreria', 'root', 'mysqlroot')\n",
    "query = \"\"\"\n",
    "    SELECT date(pedido.fecha) as 'fecha',\n",
    "        libro.titulo AS 'libro',\n",
    "        genero.nombre AS 'genero',\n",
    "        comuna.nombre AS 'comuna',\n",
    "        sum(pedido.cantidad) AS 'cantidad'\n",
    "    FROM pedido\n",
    "    INNER JOIN libro ON libro.id_libro = pedido.libro\n",
    "    INNER JOIN genero ON genero.id_genero = libro.genero\n",
    "    INNER JOIN cliente ON cliente.id_cliente = pedido.cliente\n",
    "    INNER JOIN comuna ON comuna.id_comuna = cliente.comuna\n",
    "    GROUP BY fecha, libro, genero, comuna;\n",
    "    \"\"\"\n",
    "\n",
    "name_mapping = 'fecha', 'titulo', 'genero', 'comuna', 'cantidad'\n",
    "ventas_source = SQLSource(connection=cnx_libreria, query=query, names=name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación\n",
    "\n",
    "A partir de la fecha obtenida desde la base de datos __libreria__ se obtienen nuevos atributos para poblar la dimensión __tiempo__. Para esto, se diseñan dos funciones, una para dividir la fecha y obtener los atributos __dia__, __mes__ y __año__, y la otra, para obtener el __trimestre__ al que corresponde dicha fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dmY(row):\n",
    "    \"\"\"Agrega los componentes de la fecha al registro (row)\n",
    "\n",
    "    Args:\n",
    "        row (dict): Registros que se carga en el almacen\n",
    "    \"\"\"\n",
    "\n",
    "    fecha = row['fecha']\n",
    "    row['dia'] = fecha.day\n",
    "    row['mes'] = fecha.month\n",
    "    row['anio'] = fecha.year\n",
    "\n",
    "def set_trimestre(row):\n",
    "    \"\"\"Agrega el trimestre al registro (row) \n",
    "\n",
    "    Args:\n",
    "        row (dict): Registros que se carga en el almacén\n",
    "    \"\"\"\n",
    "\n",
    "    if row['mes'] < 4:\n",
    "        trimestre = 1\n",
    "    elif row['mes'] < 7:\n",
    "        trimestre = 2\n",
    "    elif row['mes'] < 10:\n",
    "        trimestre = 3\n",
    "    else:\n",
    "        trimestre = 4\n",
    "\n",
    "    row['trimestre'] = trimestre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexion con el almacén de datos\n",
    "\n",
    "- `ConnectionWrapper` comparte automáticamente entre abstracciones de `pygrametl`, se guarda en una variable para que la conexión se pueda cerrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygrametl import ConnectionWrapper\n",
    "\n",
    "# notar que se utiliza la función conexion() creada anteriormente\n",
    "cnx_dm = conexion('localhost', 'ventas_dm', 'root', 'mysqlroot')\n",
    "cnx_dm_wrapper = ConnectionWrapper(connection=cnx_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga\n",
    "\n",
    "- `pygrametl` proporciona diversos tipos de abstracciones para dimensiones y tablas de hechos. En este ejemplo, se usan las más simples.\n",
    "- `CachedDimension` crea una instancia de para cada dimensión en el almacén de datos. \n",
    "- `CachedDimension` utiliza caché local para reducir significativamente la cantidad de solicitudes emitidas al RDBMS. \n",
    "\n",
    "Para cada dimensión, __se proporciona el nombre de la tabla de la base de datos, la clave principal de la tabla y las columnas sin clave (atributos) de la tabla__. \n",
    "\n",
    "Además, para la __dimensión de localicalizacion__, se proporciona el subconjunto de los atributos que se deben usar para buscar la clave principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygrametl.tables import CachedDimension, FactTable\n",
    "\n",
    "libro_dim = CachedDimension(\n",
    "        name='libro',\n",
    "        key='id_libro',\n",
    "        attributes=['titulo', 'genero'])\n",
    "\n",
    "tiempo_dim = CachedDimension(\n",
    "        name='tiempo',\n",
    "        key='id_tiempo',\n",
    "        attributes=['fecha', 'dia', 'mes', 'anio', 'trimestre'])\n",
    "\n",
    "localizacion_dim = CachedDimension(\n",
    "        name='localizacion',\n",
    "        key='id_localizacion',\n",
    "        attributes=['comuna', 'region'],\n",
    "        lookupatts=['comuna'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea una instancia de `FactTable` para la tabla de hechos del almacén de datos, a partir, del nombre de la tabla, una lista de columnas que constituyen la clave principal de la tabla de hechos y una lista de las medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_ft = FactTable(\n",
    "        name='ventas',\n",
    "        keyrefs=['id_libro', 'id_localizacion', 'id_tiempo'],\n",
    "        measures=['cantidad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimensión __localizacion__ se completa con datos obtenidos desde el archivo CSV, ya que el archivo contiene toda la información necesaria para ambas columnas de la tabla. Para insertar las filas se usa el método `CachedDimension.insert()`\n",
    "\n",
    "__NOTA__: Si la dimensión __localizacion__ se completara solo con los datos de la base de datos __libreria__, sería necesario actualizar el atributo de región con datos del archivo CSV cada vez que se actualicen los datos del almacen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in region_source:\n",
    "    localizacion_dim.insert({'comuna': row['Nombre Comuna'], 'region': row['Nombre Región']})\n",
    "\n",
    "region_file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se cargan los datos en las dimensiones __libro__, __tiempo__, y también en la __tabla de hechos__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ventas_source:\n",
    "    # Se divide la fecha\n",
    "    set_dmY(row)\n",
    "    \n",
    "    # Se obtiene el trimestre\n",
    "    set_trimestre(row)\n",
    "\n",
    "    # La fila se actualiza con las claves primarias correctas para \n",
    "    # cada dimensión y cualquier dato nuevo se inserta en cada una \n",
    "    # de las dimensiones al mismo tiempo.\n",
    "    row['id_libro'] = libro_dim.ensure(row)\n",
    "    row['id_tiempo'] = tiempo_dim.ensure(row)\n",
    "\n",
    "    # CachedDimension.ensure() no se utiliza para la dimensión localizacion \n",
    "    # porque ya se ha rellenado. En su lugar, se utiliza el método \n",
    "    # CachedDimension.lookup() que no inserta ningún dato y devuelve el \n",
    "    # valor None si no está disponible una fila con las búsquedas correctas. \n",
    "    # En este caso, se genera un error si falta una ubicación en el archivo \n",
    "    # CSV, ya que la recuperación no es posible.\n",
    "    row['id_localizacion'] = localizacion_dim.lookup(row)\n",
    "    if not row['id_localizacion']:\n",
    "        raise ValueError(\"La comuna no se encuentra en la dimension Localizacion\")\n",
    "\n",
    "    # Considerando que la cantidad de ordénes se presenta como un valor agregado \n",
    "    # en los registros de ventas, la fila se puede insertar en el almacén de datos. \n",
    "    # De lo contrario, se debería realizar la transformación antes de insertar.\n",
    "    ventas_ft.insert(row)\n",
    "\n",
    "# Después de que se hayan insertado todos los datos, se ordena a la conexión que se \n",
    "# confirme la inserción y luego se cierra. Esto garantiza que los datos se\n",
    "# confirmen en la base de datos y que los recursos utilizados por la conexión se\n",
    "# liberen.\n",
    "cnx_dm_wrapper.commit()\n",
    "cnx_dm_wrapper.close()\n",
    "\n",
    "# Finalmente, se cierra la conexión a la base de datos libreria\n",
    "cnx_libreria.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('etl38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabe0d710f3a253e096a9527723e238a8c0c435f5b953a78fc3c7747ee356b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
